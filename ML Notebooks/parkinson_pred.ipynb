{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson's Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under \"1. Setup and Data Loading\"\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/content/parkinson_disease.csv')\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample data:\")\n",
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nDataset Description:\")\n",
    "display(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values count:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('id').mean().reset_index()\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection based on correlation\n",
    "columns = list(df.columns)\n",
    "for col in columns:\n",
    "    if col == 'class':\n",
    "        continue\n",
    "\n",
    "    filtered_columns = [col]\n",
    "    for col1 in df.columns:\n",
    "        if((col == col1) | (col == 'class')):\n",
    "            continue\n",
    "\n",
    "        val = df[col].corr(df[col1])\n",
    "        if val > 0.7:\n",
    "            # If the correlation between the two features is more than 0.7, remove it\n",
    "            if col1 in columns:\n",
    "              columns.remove(col1)\n",
    "            continue\n",
    "        else:\n",
    "            filtered_columns.append(col1)\n",
    "\n",
    "    df = df[filtered_columns]\n",
    "print(\"Shape after correlation-based feature selection:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using SelectKBest with chi2\n",
    "X = df.drop('class', axis=1)\n",
    "X_norm = MinMaxScaler().fit_transform(X)\n",
    "selector = SelectKBest(chi2, k=30)\n",
    "selector.fit(X_norm, df['class'])\n",
    "filtered_columns = selector.get_support()\n",
    "filtered_data = X.loc[:, filtered_columns]\n",
    "filtered_data['class'] = df['class']\n",
    "df = filtered_data\n",
    "print(\"Shape after SelectKBest feature selection:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and handle class imbalance\n",
    "features = df.drop('class', axis=1)\n",
    "target = df['class']\n",
    "\n",
    "X_train, X_val,Y_train, Y_val = train_test_split(features, target,\n",
    "                                      test_size=0.2,\n",
    "                                      random_state=10)\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=1.0,\n",
    "                        random_state=0)\n",
    "X, Y = ros.fit_resample(X_train, Y_train)\n",
    "print(\"\\nShape after oversampling:\", X.shape)\n",
    "print(\"Class distribution after oversampling:\")\n",
    "print(Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another dataset loading and preprocessing\n",
    "parkinsons_data = pd.read_csv('/content/parkinsons.data')\n",
    "parkinsons_data.drop(columns=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X_parkinsons = parkinsons_data.drop(columns=['status'])\n",
    "y_parkinsons = parkinsons_data['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RFE to select top 10 features\n",
    "model_for_rfe = svm.SVC(kernel='linear')\n",
    "rfe = RFE(estimator=model_for_rfe, n_features_to_select=10)\n",
    "rfe.fit(X_parkinsons, y_parkinsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 10 features\n",
    "selected_features = X_parkinsons.columns[rfe.support_]\n",
    "print(\"\\nTop 10 selected features using RFE:\", selected_features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['class'].value_counts()\n",
    "plt.pie(x.values,\n",
    "        labels = x.index,\n",
    "        autopct='%1.1f%%')\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split using only selected features\n",
    "X_selected = X_parkinsons[selected_features]\n",
    "X_train_selected, X_test_selected, y_train_selected, y_test_selected = train_test_split(X_selected, y_parkinsons, test_size=0.2, random_state=2)\n",
    "\n",
    "# Scale the data for the SVM model\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under \"4. Model Training and Evaluation\"\n",
    "models = [LogisticRegression(class_weight='balanced'), XGBClassifier(), SVC(kernel='rbf', probability=True), RandomForestClassifier(), DecisionTreeClassifier()]\n",
    "model_performance = {}\n",
    "\n",
    "# Define ras function if it's not defined elsewhere\n",
    "def ras(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X, Y)\n",
    "    print(f'{type(model).__name__} : ')\n",
    "\n",
    "    train_preds = model.predict(X)\n",
    "    print('Training Accuracy : ', ras(Y, train_preds))\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "    val_accuracy = ras(Y_val, val_preds)\n",
    "    print('Validation Accuracy : ', val_accuracy)\n",
    "    print()\n",
    "\n",
    "    model_performance[type(model).__name__] = val_accuracy\n",
    "\n",
    "# Find the model with the best validation accuracy\n",
    "best_model_name = max(model_performance, key=model_performance.get)\n",
    "best_accuracy = model_performance[best_model_name]\n",
    "\n",
    "print(f\"The best model based on validation accuracy is: {best_model_name} with an accuracy of {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report for Logistic Regression (first model):\")\n",
    "print(classification_report(Y_val, models[0].predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the SVM model with RFE selected features\n",
    "final_model_svm = svm.SVC(kernel='linear')\n",
    "final_model_svm.fit(X_train_scaled, y_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_svm = final_model_svm.predict(X_train_scaled)\n",
    "test_pred_svm = final_model_svm.predict(X_test_scaled)\n",
    "\n",
    "print('\\nAccuracy Score on training data (SVM with top features and scaling): ', accuracy_score(y_train_selected, train_pred_svm))\n",
    "print('Accuracy Score on testing data (SVM with top features and scaling): ', accuracy_score(y_test_selected, test_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Saving and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parkinson_pred_top_features.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model_svm, f)\n",
    "print(\"SVM model trained with top 10 features saved as parkinson_pred_top_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction with the saved SVM model\n",
    "# Define the list of features your model was trained on\n",
    "model_features = ['MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:DDA', 'NHR', 'RPDE', 'DFA', 'spread1', 'spread2', 'D2', 'PPE']\n",
    "\n",
    "# Your input data (make sure these values correspond to the features above)\n",
    "# You need to provide only the values for the 10 features in model_features\n",
    "input_data_values = (0.01098, 0.09700, 0.00563, 0.01689, 0.422229, 0.741367, -7.348300, 0.177551, 1.743867, 0.085569) # Example values - REPLACE with actual values\n",
    "\n",
    "# Convert the input data to a NumPy array\n",
    "numpy_array = np.asarray(input_data_values)\n",
    "\n",
    "# Reshape the NumPy array to have 1 row and the number of features as columns\n",
    "data_reshaped = numpy_array.reshape(1, -1)\n",
    "\n",
    "# Scale the input data using the scaler fitted on the RFE selected features\n",
    "std_data = scaler.transform(data_reshaped)\n",
    "\n",
    "# Load the trained SVM model\n",
    "with open('parkinson_pred_top_features.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Make a prediction using the loaded model\n",
    "prediction = loaded_model.predict(std_data)\n",
    "\n",
    "print(\"\\nPrediction for sample input:\")\n",
    "print(prediction)\n",
    "\n",
    "if prediction[0] == 0:\n",
    "    print(\"The Person does not have Parkinsons Disease\")\n",
    "else:\n",
    "    print(\"The Person has Parkinsons\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOL63QDU6yfGwfbt5zKnHZv",
   "mount_file_id": "1NXiUKcJNwQPb4ks1OuOoqJFizi4a8XHv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
